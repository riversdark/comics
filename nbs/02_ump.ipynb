{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60725379",
   "metadata": {},
   "source": [
    "# ump\n",
    "\n",
    "> Untargeted Metabolomics Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b06cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The universal workflow for untargeted `metabolomics` always consists of\n",
    "`feature` detection in the individual MS sample files and their linkage\n",
    "to `consensus features` with common m/z and retention time values. In\n",
    "addition, there are optional steps such as adduct detection and\n",
    "annotation of `features` with associated `MS2` spectra.\n",
    "\n",
    "First, download two example `mzML` files.\n",
    "\n",
    "``` python\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "gh = \"https://raw.githubusercontent.com/OpenMS/pyopenms-docs/master\"\n",
    "urlretrieve(gh + \"/src/data/Metabolomics_1.mzML\", \"Metabolomics_1.mzML\")\n",
    "urlretrieve(gh + \"/src/data/Metabolomics_2.mzML\", \"Metabolomics_2.mzML\")\n",
    "```\n",
    "\n",
    "For each `mzML` file do mass trace, elution peak and features detection.\n",
    "\n",
    "``` python\n",
    "import pyopenms as oms\n",
    "import os\n",
    "\n",
    "mzML_files = [\"Metabolomics_1.mzML\", \"Metabolomics_2.mzML\"]\n",
    "\n",
    "feature_maps = []\n",
    "for file in mzML_files:\n",
    "    # load mzML file into MSExperiment\n",
    "    exp = oms.MSExperiment()\n",
    "    oms.MzMLFile().load(\n",
    "        file, exp\n",
    "    )  # load each mzML file to an OpenMS file format (MSExperiment)\n",
    "\n",
    "    # mass trace detection\n",
    "    mass_traces = (\n",
    "        []\n",
    "    )  # introduce an empty list where the mass traces will be loaded\n",
    "    mtd = oms.MassTraceDetection()\n",
    "    mtd_par = (\n",
    "        mtd.getDefaults()\n",
    "    )  # get the default parameters in order to edit them\n",
    "    mtd_par.setValue(\"mass_error_ppm\", 10.0)  # high-res instrument, orbitraps\n",
    "    mtd_par.setValue(\n",
    "        \"noise_threshold_int\", 1.0e04\n",
    "    )  # data-dependent (usually works for orbitraps)\n",
    "    mtd.setParameters(mtd_par)  # set the new parameters\n",
    "    mtd.run(exp, mass_traces, 0)  # run mass trace detection\n",
    "\n",
    "    # elution peak detection\n",
    "    mass_traces_deconvol = []\n",
    "    epd = oms.ElutionPeakDetection()\n",
    "    epd_par = epd.getDefaults()\n",
    "    epd_par.setValue(\n",
    "        \"width_filtering\", \"fixed\"\n",
    "    )  # The fixed setting filters out mass traces outside the [min_fwhm: 1.0, max_fwhm: 60.0] interval\n",
    "    epd.setParameters(epd_par)\n",
    "    epd.detectPeaks(mass_traces, mass_traces_deconvol)\n",
    "\n",
    "    # feature detection\n",
    "    feature_map = oms.FeatureMap()  # output features\n",
    "    chrom_out = []  # output chromatograms\n",
    "    ffm = oms.FeatureFindingMetabo()\n",
    "    ffm_par = ffm.getDefaults()\n",
    "    ffm_par.setValue(\n",
    "        \"remove_single_traces\", \"true\"\n",
    "    )  # remove mass traces without satellite isotopic traces\n",
    "    ffm.setParameters(ffm_par)\n",
    "    ffm.run(mass_traces_deconvol, feature_map, chrom_out)\n",
    "    feature_map.setUniqueIds()  # Assigns a new, valid unique id per feature\n",
    "    feature_map.setPrimaryMSRunPath(\n",
    "        [file.encode()]\n",
    "    )  # Sets the file path to the primary MS run (usually the mzML file)\n",
    "    feature_maps.append(feature_map)\n",
    "```\n",
    "\n",
    "Align features retention times based on the `feature map` with the\n",
    "highest number of features (reference map).\n",
    "\n",
    "``` python\n",
    "# use as reference for alignment, the file with the largest number of features\n",
    "# (works well if you have a pooled QC for example)\n",
    "ref_index = feature_maps.index(sorted(feature_maps, key=lambda x: x.size())[-1])\n",
    "\n",
    "aligner = oms.MapAlignmentAlgorithmPoseClustering()\n",
    "\n",
    "trafos = {}\n",
    "\n",
    "# parameter optimization\n",
    "aligner_par = aligner.getDefaults()\n",
    "aligner_par.setValue(\"max_num_peaks_considered\", -1)  # infinite\n",
    "aligner_par.setValue(\n",
    "    \"pairfinder:distance_MZ:max_difference\", 10.0\n",
    ")  # Never pair features with larger m/z distance\n",
    "aligner_par.setValue(\"pairfinder:distance_MZ:unit\", \"ppm\")\n",
    "aligner.setParameters(aligner_par)\n",
    "aligner.setReference(feature_maps[ref_index])\n",
    "\n",
    "for feature_map in feature_maps[:ref_index] + feature_maps[ref_index + 1 :]:\n",
    "    trafo = oms.TransformationDescription()  # save the transformed data points\n",
    "    aligner.align(feature_map, trafo)\n",
    "    trafos[feature_map.getMetaValue(\"spectra_data\")[0].decode()] = trafo\n",
    "    transformer = oms.MapAlignmentTransformer()\n",
    "    transformer.transformRetentionTimes(feature_map, trafo, True)\n",
    "```\n",
    "\n",
    "Align `mzML` files aligment based on :py`~.FeatureMap` alignment\n",
    "(optional, only for GNPS).\n",
    "\n",
    "``` python\n",
    "# align mzML files based on FeatureMap alignment and store as mzML files (for GNPS!)\n",
    "for file in mzML_files:\n",
    "    exp = oms.MSExperiment()\n",
    "    oms.MzMLFile().load(file, exp)\n",
    "    exp.sortSpectra(True)\n",
    "    exp.setMetaValue(\"mzML_path\", file)\n",
    "    if file not in trafos.keys():\n",
    "        oms.MzMLFile().store(file[:-5] + \"_aligned.mzML\", exp)\n",
    "        continue\n",
    "    transformer = oms.MapAlignmentTransformer()\n",
    "    trafo_description = trafos[file]\n",
    "    transformer.transformRetentionTimes(exp, trafo_description, True)\n",
    "    oms.MzMLFile().store(file[:-5] + \"_aligned.mzML\", exp)\n",
    "mzML_files = [file[:-5] + \"_aligned.mzML\" for file in mzML_files]\n",
    "```\n",
    "\n",
    "Map `MS2` spectra to features as :py`~.PeptideIdentification` objects\n",
    "(optional, only for GNPS).\n",
    "\n",
    "``` python\n",
    "feature_maps_mapped = []\n",
    "use_centroid_rt = False\n",
    "use_centroid_mz = True\n",
    "mapper = oms.IDMapper()\n",
    "for file in mzML_files:\n",
    "    exp = oms.MSExperiment()\n",
    "    oms.MzMLFile().load(file, exp)\n",
    "    for i, feature_map in enumerate(feature_maps):\n",
    "        if feature_map.getMetaValue(\"spectra_data\")[\n",
    "            0\n",
    "        ].decode() == exp.getMetaValue(\"mzML_path\"):\n",
    "            peptide_ids = []\n",
    "            protein_ids = []\n",
    "            mapper.annotate(\n",
    "                feature_map,\n",
    "                peptide_ids,\n",
    "                protein_ids,\n",
    "                use_centroid_rt,\n",
    "                use_centroid_mz,\n",
    "                exp,\n",
    "            )\n",
    "            fm_new = oms.FeatureMap(feature_map)\n",
    "            fm_new.clear(False)\n",
    "            # set unique identifiers to protein and peptide identifications\n",
    "            prot_ids = []\n",
    "            if len(feature_map.getProteinIdentifications()) > 0:\n",
    "                prot_id = feature_map.getProteinIdentifications()[0]\n",
    "                prot_id.setIdentifier(f\"Identifier_{i}\")\n",
    "                prot_ids.append(prot_id)\n",
    "            fm_new.setProteinIdentifications(prot_ids)\n",
    "            for feature in feature_map:\n",
    "                pep_ids = []\n",
    "                for pep_id in feature.getPeptideIdentifications():\n",
    "                    pep_id.setIdentifier(f\"Identifier_{i}\")\n",
    "                    pep_ids.append(pep_id)\n",
    "                feature.setPeptideIdentifications(pep_ids)\n",
    "                fm_new.push_back(feature)\n",
    "            feature_maps_mapped.append(fm_new)\n",
    "feature_maps = feature_maps_mapped\n",
    "```\n",
    "\n",
    "Detect adducts (optional, only for SIRIUS and GNPS Ion Identity\n",
    "Molecular Networking).\n",
    "\n",
    "``` python\n",
    "feature_maps_adducts = []\n",
    "for feature_map in feature_maps:\n",
    "    mfd = oms.MetaboliteFeatureDeconvolution()\n",
    "    mdf_par = mfd.getDefaults()\n",
    "    mdf_par.setValue(\n",
    "        \"potential_adducts\",\n",
    "        [\n",
    "            b\"H:+:0.4\",\n",
    "            b\"Na:+:0.2\",\n",
    "            b\"NH4:+:0.2\",\n",
    "            b\"H-1O-1:+:0.1\",\n",
    "            b\"H-3O-2:+:0.1\",\n",
    "        ],\n",
    "    )\n",
    "    mfd.setParameters(mdf_par)\n",
    "    feature_map_adduct = oms.FeatureMap()\n",
    "    mfd.compute(feature_map, feature_map_adduct, oms.ConsensusMap(), oms.ConsensusMap())\n",
    "    feature_maps_adducts.append(feature_map_adduct)\n",
    "feature_maps = feature_maps_adducts\n",
    "\n",
    "# for SIRIUS store the feature maps as featureXML files!\n",
    "for feature_map in feature_maps:\n",
    "    oms.FeatureXMLFile().store(\n",
    "        feature_map.getMetaValue(\"spectra_data\")[0].decode()[:-4]\n",
    "        + \"featureXML\",\n",
    "        feature_map,\n",
    "    )\n",
    "```\n",
    "\n",
    "Link features in a :py`~.ConsensusMap`.\n",
    "\n",
    "``` python\n",
    "feature_grouper = oms.FeatureGroupingAlgorithmKD()\n",
    "\n",
    "consensus_map = oms.ConsensusMap()\n",
    "file_descriptions = consensus_map.getColumnHeaders()\n",
    "\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    file_description = file_descriptions.get(i, oms.ColumnHeader())\n",
    "    file_description.filename = os.path.basename(\n",
    "        feature_map.getMetaValue(\"spectra_data\")[0].decode()\n",
    "    )\n",
    "    file_description.size = feature_map.size()\n",
    "    file_descriptions[i] = file_description\n",
    "\n",
    "feature_grouper.group(feature_maps, consensus_map)\n",
    "consensus_map.setColumnHeaders(file_descriptions)\n",
    "consensus_map.setUniqueIds()\n",
    "oms.ConsensusXMLFile().store(\"FeatureMatrix.consensusXML\", consensus_map)\n",
    "```\n",
    "\n",
    "To get a final feature matrix in a table format, export the\n",
    "`:consensus features<consensus feature>` in a `pandas DataFrame`.\n",
    "\n",
    "``` python\n",
    "df = consensus_map.get_df()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29669d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comics",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
